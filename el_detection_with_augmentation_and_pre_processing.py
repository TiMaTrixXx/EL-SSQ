# -*- coding: utf-8 -*-
"""EL detection with augmentation and pre-processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qQVBEMbjRAL_7Y2pf8SVP8v4-5XAjW6d

# 1. Installing Ultralytics
"""

# Install ultralytics package.

!pip install -qq ultralytics
import ultralytics

print(ultralytics.__version__)

# Commented out IPython magic to ensure Python compatibility.
DRIVE_WORKING_DIR = "/content/drive/MyDrive/Colab_AI_Team/ELDeD/EL_task/LatestV1/Yolo" # Write path for your working dir
# %cd {DRIVE_WORKING_DIR}
!ls {DRIVE_WORKING_DIR}

"""# GPU check




"""

import torch

cuda_available = torch.cuda.is_available()

if cuda_available:

  print("CUDA is available")
  !nvidia-smi

else:

  message = """
    WARNING: In order to train the model, it is advisable to use GPU.
    Change runtime type to GPU from:
      menu Runtime -> Change runtime type -> Hardware accelerator -> GPU.
      And run all the cells again.
  """
  print(message)

"""# Data Loading"""

!pip install -U gdown

# File ID extracted from the Google Drive link
!gdown --id 17HvtvBVhxXlA1zqNMtCnvseCssLNml3o --output dataset.zip

# Unzip the downloaded file
!unzip dataset.zip -d dataset_folder

"""# model training"""

import subprocess
from pathlib import Path
import shutil
import yaml

# === INPUT COCO DIR ===
source_dir = Path("dataset_folder/content/drive/MyDrive/Colab_AI_Team/ELDeD/EL_task/LatestV1/EL_dataset_6_class_WithContrast/Sliced_Dataset_only_instance")
train_json = source_dir / "train_5C.json"
val_json = source_dir / "val_5C.json"

# === OUTPUT DIR ===
output_dir = Path("dataset_folder/content/dataset")
train_out = output_dir / "train"
val_out = output_dir / "val"

train_img= train_out / "images"
val_img= val_out / "images"
train_lab= train_out / "labels"
val_lab= val_out / "labels"

# === Copy images ===
def copy_images(src_img_dir, dst_img_dir):
    dst_img_dir.mkdir(parents=True, exist_ok=True)
    for file in Path(src_img_dir).glob("*.*"):
        if file.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            shutil.copy(file, dst_img_dir / file.name)

copy_images(source_dir / "train", train_img)
copy_images(source_dir / "val", val_img)

import json
import os
from tqdm import tqdm
def coco_to_yolo(coco_json_path, output_folder):
    with open(coco_json_path) as f:
        data = json.load(f)

    images = {img['id']: img for img in data['images']}
    categories = {cat['id']: i for i, cat in enumerate(data['categories'])}

    os.makedirs(output_folder, exist_ok=True)

    for ann in tqdm(data['annotations'], desc="Converting"):
        image_id = ann['image_id']
        image_info = images[image_id]
        image_w = image_info['width']
        image_h = image_info['height']

        x_min, y_min, width, height = ann['bbox']
        x_center = (x_min + width / 2) / image_w
        y_center = (y_min + height / 2) / image_h
        width /= image_w
        height /= image_h

        class_id = categories[ann['category_id']]

        label_filename = os.path.splitext(image_info['file_name'])[0] + '.txt'
        label_path = os.path.join(output_folder, label_filename)

        with open(label_path, 'a') as f:
            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")

    print(f"Conversion completed. Labels saved to: {output_folder}")

coco_to_yolo(train_json, train_lab)
coco_to_yolo(val_json, val_lab)

import json
import yaml
from pathlib import Path

def create_data_yaml(coco_json_path, dataset_root="dataset_folder/content/dataset", yaml_filename="/content/dataset/data.yaml"):
    with open(coco_json_path) as f:
        coco = json.load(f)

    # extract category names
    categories = sorted(coco["categories"], key=lambda x: x["id"])
    names = [cat["name"] for cat in categories]

    yaml_dict = {
        "path": dataset_root,
        "train": "train/images",
        "val": "val/images",
        "nc": len(names),
        "names": names
    }

    yaml_path = 'data_el.yaml'
    with open(yaml_path, "w") as f:
        yaml.dump(yaml_dict, f)

    print(f"✅ data.yaml written to: {yaml_path}")

# Example usage
source_dir = Path("dataset_folder/content/drive/MyDrive/Colab_AI_Team/ELDeD/EL_task/LatestV1/EL_dataset_6_class_WithContrast/Sliced_Dataset_only_instance")
train_json = source_dir / "train_5C.json"
val_json = source_dir / "val_5C.json"
create_data_yaml(val_json)

import cv2
import os
import matplotlib.pyplot as plt
from glob import glob
import numpy as np

# 1️⃣ Define preprocessing functions
def apply_clahe(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    merged = cv2.merge([cl, a, b])
    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)

def gamma_correction(img, gamma=0.5):
    inv = 1.0 / gamma
    table = (np.arange(256) / 255.0) ** inv * 255
    table = table.astype('uint8')
    return cv2.LUT(img, table)

def unsharp_mask(img):
    blur = cv2.GaussianBlur(img, (0,0), sigmaX=3)
    return cv2.addWeighted(img, 1.5, blur, -0.5, 0)

def bg_subtract(img):
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31,31))
    bg = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)
    sub = cv2.subtract(img, bg)
    return cv2.add(sub, 30)  # offset to avoid pure black

# 2️⃣ Compose them
def preprocess(img):
    img = apply_clahe(img)
    img = gamma_correction(img, gamma=0.6)
    #img = unsharp_mask(img)
    #img = bg_subtract(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img

# 3️⃣ Visualize a few samples
TRAIN_DIR = '/content/dataset_folder/content/drive/MyDrive/Colab_AI_Team/ELDeD/EL_task/LatestV1/EL_dataset_6_class_WithContrast/Sliced_Dataset_only_instance/train'
sample_paths = glob(os.path.join(TRAIN_DIR, '*'))[:50]

for path in sample_paths:
    orig = cv2.imread(path)
    proc = preprocess(orig)
    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1)
    plt.imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))
    plt.title('Original'); plt.axis('off')
    plt.subplot(1,2,2)
    plt.imshow(cv2.cvtColor(proc, cv2.COLOR_BGR2RGB))
    plt.title('Preprocessed'); plt.axis('off')
    plt.show()

import cv2
import os
import matplotlib.pyplot as plt
from glob import glob
import numpy as np

# 1️⃣ Extended preprocessing functions

def apply_clahe(img):
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    merged = cv2.merge([cl, a, b])
    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)

def gamma_correction(img, gamma=0.5):
    inv = 1.0 / gamma
    table = (np.arange(256) / 255.0) ** inv * 255
    table = table.astype('uint8')
    return cv2.LUT(img, table)

def unsharp_mask(img):
    blur = cv2.GaussianBlur(img, (0,0), sigmaX=3)
    return cv2.addWeighted(img, 1.5, blur, -0.5, 0)

def bg_subtract(img):
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31,31))
    bg = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)
    sub = cv2.subtract(img, bg)
    return cv2.add(sub, 30)

def top_hat(img, ksize=15):
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    return cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)

def black_hat(img, ksize=15):
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))
    return cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)

def gabor_filters(ksize=21, sigma=5.0, lambd=10.0, gamma=0.5):
    filters = []
    for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:
        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, 0, ktype=cv2.CV_32F)
        kern /= 1.5*kern.sum()
        filters.append(kern)
    return filters

def apply_gabor(img, filters):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    responses = [cv2.filter2D(gray, cv2.CV_8UC3, kern) for kern in filters]
    max_resp = np.max(np.stack(responses, axis=-1), axis=-1)
    return cv2.cvtColor(max_resp, cv2.COLOR_GRAY2BGR)

def adaptive_crack_mask(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    th = cv2.adaptiveThreshold(gray, 255,
                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY_INV, 51, 5)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    clean = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1)
    # convert mask to 3-channel for visualization
    return cv2.cvtColor(clean, cv2.COLOR_GRAY2BGR)

def belt_mark_overlay(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=80,
                            minLineLength=100, maxLineGap=10)
    overlay = img.copy()
    if lines is not None:
        for x1, y1, x2, y2 in lines[:,0]:
            cv2.line(overlay, (x1,y1), (x2,y2), (0,0,255), 2)
    return overlay

# 2️⃣ Compose a unified preprocess pipeline

gabor_kernels = gabor_filters()

def preprocess(img):
    img = apply_clahe(img)
    img = gamma_correction(img, gamma=0.6)
    img = unsharp_mask(img)
    img = top_hat(img, ksize=15)
    img = black_hat(img, ksize=15)
    img = apply_gabor(img, gabor_kernels)
    # mask visualization appended as alpha if needed:
    mask = adaptive_crack_mask(img)
    overlay = belt_mark_overlay(img)
    # Stack original + mask + overlay for composite view
    composite = np.hstack([img, mask, overlay])
    return img

# 3️⃣ Visualize many samples

TRAIN_DIR = '/content/dataset_folder/content/drive/MyDrive/Colab_AI_Team/ELDeD/EL_task/LatestV1/EL_dataset_6_class_WithContrast/Sliced_Dataset_only_instance/train'
sample_paths = glob(os.path.join(TRAIN_DIR, '*'))[:50]

for path in sample_paths:
    orig = cv2.imread(path)
    proc = preprocess(orig)
    plt.figure(figsize=(15,5))
    plt.imshow(cv2.cvtColor(proc, cv2.COLOR_BGR2RGB))
    plt.title('Preprocessed Original | Crack Mask | Belt Overlay'); plt.axis('off')
    plt.show()

from ultralytics import YOLO
import yaml

# Load the YOLO model
model = YOLO("yolov8s.pt")

# # Load hyperparameters from YAML file (if you did hypertunning)
# with open("/content/drive/MyDrive/runs/detect/tune/best_hyperparameters.yaml", "r") as f:
#     hyp_params = yaml.safe_load(f)

# Train the model with hyperparameter overrides
model.train(
    data='data_el.yaml',
    epochs=50,
    imgsz=[512, 640]
    batch=16,
    lr0=0.006,
    lrf = 0.5
    optimizer='AdamW',
   # lr_scheduler='cosine',
    patience=5,
    device=0,
    project='el_yolo8',
    name='runs',
    exist_ok=True,
    verbose=True,

    # --- augmentation & mixing ---
    augment=True,
    mosaic=0.5,
    mixup=0.5,
    flipud=0.0,
    fliplr=0.5,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=0.0,
    translate=0.1,
    scale=0.5,
    shear=0.0,

    # --- class balance & recall ---
#    repeat=5,
    conf=0.001,
    iou=0.65,

    # --- loss gains (VarifocalLoss) ---
    box=0.05,
    cls=0.5,
    dfl=1.5,
)

"""Next set"""

from ultralytics import YOLO
import yaml

# Load the YOLO model
model = YOLO("yolov8s.pt")

model.train(
    data='data_el.yaml',
    epochs=30,

    # — Multi‐scale input sizes —
    imgsz=[512, 640, 768],  # randomly pick one per batch
    batch=12,               # adjust to GPU memory

    # — Optimizer & LR schedule (one‐cycle style) —
    optimizer='AdamW',
    lr0=0.006,              # initial LR
    lrf=0.2,                # final LR = lr0 * 0.2
    warmup_epochs=3.0,      # linear warmup over first 3 epochs
    warmup_bias_lr=0.1,
    warmup_momentum=0.8,
    #nef=3.0,                # freeze first backbone layers for 3 epochs

    # — Augmentation (strong but randomized) —
    augment=True,
    mosaic=0.5,
    mixup=0.5,
    fliplr=0.5,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    translate=0.1,
    scale=0.2,
    shear=0.0,

    # — Recall focus during training & val —
    conf=0.001,
    iou=0.65,

    # — Loss gains (VarifocalLoss tuning) —
    box=0.1,
    cls=1.0,
    dfl=1.0,

    # — Exponential Moving Average of weights —
 #   ema=True,

    # — Logging & checkpoints —
    project='el_yolo8',
    name='one_shot',
    exist_ok=True,
    verbose=True,
)

model.train(
    data='data_el.yaml',
    epochs=10,       # this is additional epochs (total now 5+10=15)
    imgsz=640,
    batch=16,        # maybe reduce batch to fit GPU
    lr0=0.005,
    lrf=0.2,
    mosaic=0.3,
    mixup=0.3,
    translate=0.1,
    scale=0.2,
    project='el_yolo8',
    name='phase2_640',
    exist_ok=True,
)